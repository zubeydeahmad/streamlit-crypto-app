# main_app.py
# (Ana Streamlit UygulamasÄ±)
# Bu dosya Streamlit arayÃ¼zÃ¼nÃ¼ oluÅŸturur, veri Ã§ekme, model eÄŸitimi ve tahmin sÃ¼reÃ§lerini entegre eder.
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta, time # 'time' objesini import etmeyi unutmayÄ±n
import joblib
from sklearn.preprocessing import MinMaxScaler
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
import numpy as np
import plotly.graph_objects as go
import logging
import os
import sys

# data_fetcher.py'nin bulunduÄŸu dizini sys.path'e ekleyin
# (Proje yapÄ±sÄ±na gÃ¶re bu yolu ayarlamanÄ±z gerekebilir)
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
import data_fetcher as df # data_fetcher.py dosyasÄ±nÄ± df olarak import ediyoruz

# Loglama yapÄ±landÄ±rmasÄ±
logging.basicConfig(filename='crypto_app.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', encoding='utf-8')
logger = logging.getLogger(__name__)

# Streamlit sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(layout="wide", page_title="Finansal VarlÄ±k Analiz ve Tahmin UygulamasÄ±", page_icon="ğŸ“ˆ")

# BaÅŸlÄ±k
st.title("ğŸ“ˆ Finansal VarlÄ±k Analiz ve Tahmin UygulamasÄ±")
st.markdown("Bu uygulama ile Ã§eÅŸitli finansal varlÄ±klarÄ±n geÃ§miÅŸ verilerini analiz edebilir, modelleyebilir ve gelecek fiyatlarÄ±nÄ± tahmin edebilirsiniz.")

# --- Sabitler ve Ayarlar ---
FEATURE_LAG = 7 # Modelin kullanacaÄŸÄ± geÃ§miÅŸ gÃ¼n sayÄ±sÄ± (Ã¶zellikler iÃ§in)
TARGET_LAG = 1 # 1 gÃ¼n sonrasÄ± iÃ§in tahmin

# --- YardÄ±mcÄ± Fonksiyonlar ---
# Caching key'e asset_symbol ve tarih aralÄ±klarÄ± ekleyerek, her farklÄ± Ã§aÄŸrÄ±da yeniden veri Ã§ekilmesini saÄŸla
@st.cache_data(show_spinner="GeÃ§miÅŸ veriler Ã§ekiliyor...", ttl=timedelta(hours=1))
def get_historical_data(asset_symbol: str, asset_source: str, start_date: datetime, end_date: datetime) -> pd.DataFrame:
    """Belirtilen varlÄ±k iÃ§in geÃ§miÅŸ verileri Ã§eker."""
    logger.info(f"get_historical_data Ã§aÄŸrÄ±ldÄ±: Sembol={asset_symbol}, Kaynak={asset_source}, BaÅŸlangÄ±Ã§={start_date.strftime('%Y-%m-%d')}, BitiÅŸ={end_date.strftime('%Y-%m-%d')}")
    try:
        if asset_source == "yfinance":
            data = df.get_yfinance_data(asset_symbol, start_date, end_date)
        elif asset_source == "coinapi":
            # CoinAPI sembolleri genellikle BTC, ETH gibi 'base' currency formatÄ±ndadÄ±r.
            # Yfinance'daki BTC-USD gibi sembolleri burada da uyumlu hale getirmemiz gerekebilir.
            # Åimdilik, CoinAPI iÃ§in doÄŸrudan asset_symbol kullanacaÄŸÄ±z.
            base_currency = asset_symbol.split('-')[0] if '-' in asset_symbol else asset_symbol
            data = df.get_coinapi_data(base_currency, days_back=(end_date - start_date).days)
        else:
            st.error("Bilinmeyen veri kaynaÄŸÄ±.")
            return pd.DataFrame()
        
        logger.debug(f"get_historical_data: '{asset_symbol}' iÃ§in Ã§ekilen veri boÅŸ mu? {data.empty}")
        if not data.empty:
            logger.debug(f"get_historical_data: '{asset_symbol}' iÃ§in Ã§ekilen veri boyutu: {data.shape}")
            logger.debug(f"get_historical_data: '{asset_symbol}' iÃ§in ilk 5 satÄ±r:\n{data.head()}")
        
        return data
    except Exception as e:
        logger.error(f"GeÃ§miÅŸ veri Ã§ekilirken hata oluÅŸtu ({asset_symbol}): {e}")
        st.error(f"GeÃ§miÅŸ veri Ã§ekilirken hata oluÅŸtu: {e}")
        return pd.DataFrame()

# Preprocessing ve Feature Engineering
@st.cache_data(show_spinner="Veriler iÅŸleniyor...", ttl=timedelta(hours=1))
def preprocess_data(data: pd.DataFrame, asset_symbol: str) -> pd.DataFrame:
    """Veriye Ã¶zellik mÃ¼hendisliÄŸi uygular ve temizler."""
    logger.info(f"preprocess_data Ã§aÄŸrÄ±ldÄ± for {asset_symbol}. Gelen veri boyutu: {data.shape}")
    if data.empty:
        logger.warning(f"Preprocess for {asset_symbol}: BoÅŸ DataFrame geldi.")
        return pd.DataFrame()

    df_processed = data.copy()
    
    # Tarih indeksini saÄŸlamlaÅŸtÄ±r
    df_processed.index = pd.to_datetime(df_processed.index)
    df_processed = df_processed.sort_index()

    # Eksik gÃ¼nleri tamamla ve NaN deÄŸerleri Ã¶nceki deÄŸerle doldur
    # Bu adÄ±m, Ã¶zellikle yfinance'dan gelen ve haftasonu/tatil eksikliÄŸi olan veriler iÃ§in Ã¶nemli
    # Reindex yapmadan Ã¶nce en kÃ¼Ã§Ã¼k ve en bÃ¼yÃ¼k tarihi belirle
    min_date = df_processed.index.min()
    max_date = df_processed.index.max()
    full_date_range = pd.date_range(start=min_date, end=max_date, freq='D')
    
    df_processed = df_processed.reindex(full_date_range)
    
    # Ä°leriye doÄŸru doldur (ffill) ve sonra geriye doÄŸru doldur (bfill)
    # Bu, herhangi bir baÅŸlangÄ±Ã§taki NaN'larÄ± da doldurur.
    df_processed.fillna(method='ffill', inplace=True)
    df_processed.fillna(method='bfill', inplace=True) # BaÅŸlangÄ±Ã§taki NaN'larÄ± doldurmak iÃ§in

    # Ortalama Fiyat
    df_processed['Avg_Price'] = (df_processed['Open'] + df_processed['Close']) / 2

    # Hareketli Ortalamalar
    df_processed['MA7'] = df_processed['Close'].rolling(window=7).mean()
    df_processed['MA21'] = df_processed['Close'].rolling(window=21).mean()

    # RSI (GÃ¶receli GÃ¼Ã§ Endeksi)
    # RSI hesaplamasÄ± iÃ§in gerekli minimum veri: 14 periyot
    if len(df_processed) >= 14:
        delta = df_processed['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df_processed['RSI'] = 100 - (100 / (1 + rs))
    else:
        df_processed['RSI'] = np.nan
        logger.warning(f"Preprocess for {asset_symbol}: RSI hesaplamak iÃ§in yeterli veri yok (min 14 gÃ¼n gerekli).")

    # MACD
    # MACD hesaplamasÄ± iÃ§in gerekli minimum veri: 26 periyot
    if len(df_processed) >= 26:
        exp1 = df_processed['Close'].ewm(span=12, adjust=False).mean()
        exp2 = df_processed['Close'].ewm(span=26, adjust=False).mean()
        df_processed['MACD'] = exp1 - exp2
        df_processed['Signal_Line'] = df_processed['MACD'].ewm(span=9, adjust=False).mean()
    else:
        df_processed['MACD'] = np.nan
        df_processed['Signal_Line'] = np.nan
        logger.warning(f"Preprocess for {asset_symbol}: MACD hesaplamak iÃ§in yeterli veri yok (min 26 gÃ¼n gerekli).")

    # GÃ¼nlÃ¼k Getiri
    df_processed['Daily_Return'] = df_processed['Close'].pct_change()

    # Belirli bir gecikme iÃ§in kaydÄ±rma
    # Son Fiyat (t-1), (t-2), ... (t-FEATURE_LAG)
    for i in range(1, FEATURE_LAG + 1):
        df_processed[f'Close_Lag_{i}'] = df_processed['Close'].shift(i)
        df_processed[f'Open_Lag_{i}'] = df_processed['Open'].shift(i)
        df_processed[f'High_Lag_{i}'] = df_processed['High'].shift(i)
        df_processed[f'Low_Lag_{i}'] = df_processed['Low'].shift(i)
        df_processed[f'Volume_Lag_{i}'] = df_processed['Volume'].shift(i)
        df_processed[f'Avg_Price_Lag_{i}'] = df_processed['Avg_Price'].shift(i)

    # Hedef DeÄŸiÅŸken (1 gÃ¼n sonraki kapanÄ±ÅŸ fiyatÄ±)
    df_processed['Target_Close'] = df_processed['Close'].shift(-TARGET_LAG)

    # NaN deÄŸerleri temizle (Ã¶zellikle ilk FEATURE_LAG gÃ¼nleri ve gÃ¶stergelerin baÅŸlangÄ±cÄ±)
    # Gerekli minimum veri miktarÄ±nÄ± hesapla
    min_rows_needed = max(FEATURE_LAG, 26) + 1 # En bÃ¼yÃ¼k lag (26 for MACD) + 1 (target)
    if len(df_processed) < min_rows_needed:
        logger.warning(f"Preprocess for {asset_symbol}: NaN temizliÄŸi sonrasÄ± veri boÅŸ kalabilir, minimum {min_rows_needed} satÄ±r gerekli, {len(df_processed)} mevcut.")
        st.warning(f"SeÃ§ilen tarih aralÄ±ÄŸÄ± iÃ§in yeterli veri bulunamadÄ±. LÃ¼tfen daha uzun bir tarih aralÄ±ÄŸÄ± seÃ§in (en az {min_rows_needed} gÃ¼n).")
        return pd.DataFrame()

    df_processed.dropna(inplace=True)
    
    if df_processed.empty:
        logger.error(f"Preprocess for {asset_symbol}: Ä°ÅŸleme sonrasÄ± DataFrame boÅŸ kaldÄ±.")
        st.error("Veri iÅŸleme sonrasÄ± boÅŸ kaldÄ±. LÃ¼tfen veri kaynaÄŸÄ±nÄ± ve tarih aralÄ±ÄŸÄ±nÄ± kontrol edin.")

    logger.info(f"preprocess_data tamamlandÄ± for {asset_symbol}. Son veri boyutu: {df_processed.shape}")
    logger.debug(f"preprocess_data for {asset_symbol}: Ä°ÅŸlenmiÅŸ verinin ilk 5 satÄ±rÄ±:\n{df_processed.head()}")
    logger.debug(f"preprocess_data for {asset_symbol}: Ä°ÅŸlenmiÅŸ verinin son 5 satÄ±rÄ±:\n{df_processed.tail()}")
    
    return df_processed

# Model EÄŸitimi ve Tahmin
def model_training_and_prediction(df_processed: pd.DataFrame, asset_name: str, num_future_days_to_predict: int):
    """Modeli eÄŸitir ve tahminler yapar."""
    logger.info(f"model_training_and_prediction Ã§aÄŸrÄ±ldÄ± for {asset_name}. Gelen veri boyutu: {df_processed.shape}, Tahmin gÃ¼n sayÄ±sÄ±: {num_future_days_to_predict}")
    
    if df_processed.empty:
        st.warning(f"Ä°ÅŸlenmiÅŸ veri boÅŸ, model {asset_name} iÃ§in eÄŸitilemiyor veya tahmin yapÄ±lamÄ±yor.")
        logger.warning(f"Model eÄŸitimi/tahmini: {asset_name} iÃ§in iÅŸlenmiÅŸ veri boÅŸ.")
        return None, None, None, None, None

    # Ã–zellikler listesini tanÄ±mla
    base_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Avg_Price', 'MA7', 'MA21', 'RSI', 'MACD', 'Signal_Line', 'Daily_Return']
    lag_features = [f'{col}_Lag_{i}' for i in range(1, FEATURE_LAG + 1) for col in ['Close', 'Open', 'High', 'Low', 'Volume', 'Avg_Price']]
    features = [f for f in base_features + lag_features if f in df_processed.columns] # Sadece DataFrame'de olanlarÄ± al

    target = 'Target_Close'

    # Hedef deÄŸiÅŸkenin Ã¶zellik listesinde olmadÄ±ÄŸÄ±ndan emin ol
    if target in features:
        features.remove(target)
    
    # TÃ¼m gerekli sÃ¼tunlarÄ±n DataFrame'de olduÄŸundan emin ol
    missing_features = [f for f in features if f not in df_processed.columns]
    if missing_features:
        logger.error(f"Model eÄŸitimi: {asset_name} iÃ§in eksik Ã¶zellik sÃ¼tunlarÄ±: {missing_features}")
        st.error(f"Model eÄŸitimi iÃ§in gerekli bazÄ± veri sÃ¼tunlarÄ± eksik: {', '.join(missing_features)}. LÃ¼tfen veri iÅŸleme adÄ±mÄ±nÄ± kontrol edin.")
        return None, None, None, None, None

    # NaN iÃ§eren feature'larÄ± kontrol et
    nan_in_features = df_processed[features].isnull().sum().sum()
    if nan_in_features > 0:
        logger.error(f"Model eÄŸitimi: {asset_name} iÃ§in Ã¶zelliklerde NaN deÄŸerler var. EÄŸitim durduruldu. Toplam NaN: {nan_in_features}. Detay: {df_processed[features].isnull().sum()[df_processed[features].isnull().sum() > 0].index.tolist()}")
        st.error(f"Model eÄŸitimi iÃ§in gerekli verilerde eksiklikler var. LÃ¼tfen verilerinizi kontrol edin. Eksik Ã–zellikler: {df_processed[features].isnull().sum()[df_processed[features].isnull().sum() > 0].index.tolist()}")
        return None, None, None, None, None

    X = df_processed[features]
    y = df_processed[target]

    # Veriyi eÄŸitim ve test setlerine ayÄ±r
    train_size = len(X) - FEATURE_LAG
    if train_size <= 0:
        st.warning(f"EÄŸitim iÃ§in yeterli veri yok. En az {FEATURE_LAG + 1} gÃ¼n gereklidir.")
        logger.warning(f"Model eÄŸitimi: {asset_name} iÃ§in yeterli veri yok. {len(X)} satÄ±r var, {FEATURE_LAG} gerekli.")
        return None, None, None, None, None

    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    logger.info(f"Model EÄŸitimi Ä°Ã§in {asset_name}: X_train boyutu: {X_train.shape}, y_train boyutu: {y_train.shape}")
    logger.info(f"Model Tahmini Ä°Ã§in {asset_name}: X_test boyutu: {X_test.shape}, y_test boyutu: {y_test.shape}")


    # Ã–lÃ§ekleyiciyi kaydetmek iÃ§in dosya yolu
    scaler_path = "scaler.joblib"
    features_path = "features.joblib"

    try:
        # Veriyi Ã¶lÃ§ekle
        scaler = MinMaxScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Ã–lÃ§ekleyiciyi ve Ã¶zellik listesini kaydet
        joblib.dump(scaler, scaler_path)
        joblib.dump(features, features_path)
        logger.info(f"Ã–lÃ§ekleyici ve Ã¶zellik listesi kaydedildi: {scaler_path}, {features_path}")

        # XGBoost modelini eÄŸit
        model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
        model.fit(X_train_scaled, y_train)

        # Modeli kaydet
        model_path = "xgboost_model.joblib"
        joblib.dump(model, model_path)
        logger.info(f"Model kaydedildi: {model_path}")

        # Test seti Ã¼zerinde tahmin yap
        y_pred_test = model.predict(X_test_scaled)

        # RMSE hesapla
        rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        logger.info(f"Model eÄŸitimi ve tahmini tamamlandÄ± for {asset_name}. RMSE: {rmse}")

        # Gelecek Tahmini iÃ§in son gÃ¼n verisini al
        last_data_point = df_processed[features].iloc[[-1]].copy() # Son satÄ±rÄ± DataFrame olarak al
        
        if last_data_point.empty:
            logger.error(f"Gelecek tahmin iÃ§in son veri noktasÄ± {asset_name} bulunamadÄ±.")
            return model, scaler, features, None, rmse

        future_predictions = []
        current_features_df = last_data_point # Ä°lk tahmin iÃ§in son gerÃ§ek veri

        for i in range(num_future_days_to_predict): # KullanÄ±cÄ±nÄ±n belirlediÄŸi gÃ¼n sayÄ±sÄ± kadar tahmin yap
            # Ã–zellikleri Ã¶lÃ§ekle
            current_features_scaled = scaler.transform(current_features_df)
            
            # Tahmin yap
            next_day_prediction = model.predict(current_features_scaled)[0]
            future_predictions.append(next_day_prediction)
            
            # Bir sonraki tahmin iÃ§in 'current_features_df'yi gÃ¼ncelle
            new_row_dict = {}
            
            # Mevcut kapanÄ±ÅŸ deÄŸerini al (ilk iterasyon iÃ§in son gerÃ§ek kapanÄ±ÅŸ, sonrasÄ± iÃ§in Ã¶nceki tahmin)
            current_actual_close_for_lag = current_features_df['Close'].iloc[0] 
            
            # GÃ¼ncel KapanÄ±ÅŸ, AÃ§Ä±lÄ±ÅŸ, YÃ¼ksek, DÃ¼ÅŸÃ¼k, Hacim, Ortalama Fiyat (tahmin edilen deÄŸerler)
            new_row_dict['Close'] = next_day_prediction
            new_row_dict['Open'] = next_day_prediction * (1 + np.random.uniform(-0.005, 0.005)) 
            new_row_dict['High'] = next_day_prediction * (1 + np.random.uniform(0.001, 0.01))
            new_row_dict['Low'] = next_day_prediction * (1 - np.random.uniform(0.001, 0.01))
            new_row_dict['Volume'] = current_features_df['Volume'].iloc[0] # Hacmi sabit tut (basitlik iÃ§in)

            new_row_dict['Avg_Price'] = (new_row_dict['Open'] + new_row_dict['Close']) / 2
            
            # Lag Ã¶zelliklerini gÃ¼ncelle (t-1'den t-FEATURE_LAG'e kadar kaydÄ±r)
            for lag in range(1, FEATURE_LAG):
                for col_name in ['Close', 'Open', 'High', 'Low', 'Volume', 'Avg_Price']:
                    new_row_dict[f'{col_name}_Lag_{lag+1}'] = current_features_df[f'{col_name}_Lag_{lag}'].iloc[0]
            
            # Lag_1 (yani bir Ã¶nceki gÃ¼nÃ¼n deÄŸeri) ÅŸimdiki unlagged deÄŸerler olur
            new_row_dict['Close_Lag_1'] = current_actual_close_for_lag
            new_row_dict['Open_Lag_1'] = current_features_df['Open'].iloc[0]
            new_row_dict['High_Lag_1'] = current_features_df['High'].iloc[0]
            new_row_dict['Low_Lag_1'] = current_features_df['Low'].iloc[0]
            new_row_dict['Volume_Lag_1'] = current_features_df['Volume'].iloc[0]
            new_row_dict['Avg_Price_Lag_1'] = current_features_df['Avg_Price'].iloc[0]

            # GÃ¶stergeleri gÃ¼ncelle (basit yaklaÅŸÄ±mlar)
            # MA'lar: Tahmin edilen kapanÄ±ÅŸÄ± kullanarak basit bir ÅŸekilde gÃ¼ncelle
            new_row_dict['MA7'] = (current_features_df['MA7'].iloc[0] * 6 + next_day_prediction) / 7
            new_row_dict['MA21'] = (current_features_df['MA21'].iloc[0] * 20 + next_day_prediction) / 21
            
            # RSI, MACD, Signal_Line: Bunlar iÃ§in karmaÅŸÄ±k geÃ§miÅŸ veri serisi gerektiÄŸinden, 
            # ÅŸimdilik son bilinen deÄŸerleri kullanacaÄŸÄ±z veya basit bir eÄŸilim varsayacaÄŸÄ±z.
            new_row_dict['RSI'] = current_features_df['RSI'].iloc[0] if 'RSI' in current_features_df.columns and not pd.isna(current_features_df['RSI'].iloc[0]) else np.nan
            new_row_dict['MACD'] = current_features_df['MACD'].iloc[0] if 'MACD' in current_features_df.columns and not pd.isna(current_features_df['MACD'].iloc[0]) else np.nan
            new_row_dict['Signal_Line'] = current_features_df['Signal_Line'].iloc[0] if 'Signal_Line' in current_features_df.columns and not pd.isna(current_features_df['Signal_Line'].iloc[0]) else np.nan
            
            # GÃ¼nlÃ¼k Getiri
            new_row_dict['Daily_Return'] = (next_day_prediction - current_actual_close_for_lag) / current_actual_close_for_lag if current_actual_close_for_lag != 0 else 0

            # Yeni DataFrame'i oluÅŸtururken indeks ve sÃ¼tun sÄ±rasÄ±nÄ± koru
            current_features_df = pd.DataFrame([new_row_dict], columns=features)
            
        return model, scaler, features, future_predictions, rmse

    except Exception as e:
        logger.error(f"Model eÄŸitimi veya tahmini sÄ±rasÄ±nda hata oluÅŸtu ({asset_name}): {e}")
        st.error(f"Model eÄŸitimi veya tahmini sÄ±rasÄ±nda hata oluÅŸtu: {e}. LÃ¼tfen log dosyasÄ±na bakÄ±n.")
        return None, None, None, None, None

# --- Streamlit ArayÃ¼zÃ¼ ---

# Sol sÃ¼tun: VarlÄ±k SeÃ§imi ve Tarih AralÄ±ÄŸÄ±
with st.sidebar:
    st.header("VarlÄ±k SeÃ§imi ve Ayarlar")

    # VarlÄ±k SeÃ§imi
    asset_options = list(df.VARLIK_BILGILERI.keys())
    selected_asset = st.selectbox("Analiz edilecek varlÄ±ÄŸÄ± seÃ§in:", asset_options, key="asset_select")

    # Tarih AralÄ±ÄŸÄ±
    end_date = datetime.now()
    min_days_for_training = max(FEATURE_LAG, 26) + TARGET_LAG + 5 
    start_date_default = end_date - timedelta(days=365*5) 

    start_date_input = st.date_input("BaÅŸlangÄ±Ã§ Tarihi:", value=start_date_default, max_value=end_date - timedelta(days=min_days_for_training), key="start_date_input") 
    end_date_input = st.date_input("BitiÅŸ Tarihi:", value=end_date, max_value=end_date, min_value=start_date_input + timedelta(days=min_days_for_training), key="end_date_input")

    if start_date_input >= end_date_input:
        st.error("BitiÅŸ tarihi baÅŸlangÄ±Ã§ tarihinden sonra olmalÄ±dÄ±r.")
    
    if (end_date_input - start_date_input).days < min_days_for_training:
        st.warning(f"Model eÄŸitimi iÃ§in en az {min_days_for_training} gÃ¼nlÃ¼k veri gereklidir. LÃ¼tfen tarih aralÄ±ÄŸÄ±nÄ± geniÅŸletin.")

    # Gelecek Tahmini Ä°Ã§in GÃ¼n SayÄ±sÄ±
    prediction_days = st.number_input(
        "Gelecek kaÃ§ gÃ¼n iÃ§in tahmin yapÄ±lsÄ±n?",
        min_value=1,
        max_value=30, 
        value=7,
        step=1,
        help="Modelin kaÃ§ gÃ¼n sonrasÄ±nÄ± tahmin etmesini istediÄŸinizi belirtin. (1-30 gÃ¼n arasÄ±)"
    )

    st.markdown("---")
    st.write("Verileri Ã‡ek, Modeli EÄŸit ve Tahmin Yap")
    
    # Butona basÄ±ldÄ±ÄŸÄ±nda session_state'i gÃ¼ncelle
    if st.button("UygulamayÄ± Ã‡alÄ±ÅŸtÄ±r", use_container_width=True, key="run_button"):
        st.session_state['run_analysis'] = True
        st.session_state['selected_asset_for_run'] = selected_asset
        st.session_state['start_date_for_run'] = start_date_input
        st.session_state['end_date_for_run'] = end_date_input
        st.session_state['prediction_days_for_run'] = prediction_days
    
    # EÄŸer ilk kez aÃ§Ä±lÄ±yorsa veya run_analysis False ise, hiÃ§bir ÅŸey yapma
    if 'run_analysis' not in st.session_state:
        st.session_state['run_analysis'] = False

# Ana BÃ¶lÃ¼m
if st.session_state.get('run_analysis', False):
    current_selected_asset = st.session_state['selected_asset_for_run']
    current_start_date = st.session_state['start_date_for_run']
    current_end_date = st.session_state['end_date_for_run']
    current_prediction_days = st.session_state['prediction_days_for_run']

    st.subheader(f"SeÃ§ilen VarlÄ±k: {current_selected_asset}")
    
    asset_info = df.VARLIK_BILGILERI[current_selected_asset]
    asset_symbol = asset_info["sembol"]
    asset_source = asset_info["kaynak"]

    st.info(f"'{current_selected_asset}' ({asset_symbol}) iÃ§in veriler Ã§ekiliyor ve analiz ediliyor...")

    # datetime.combine iÃ§in datetime.time.max kullanÄ±ldÄ±
    historical_data = get_historical_data(asset_symbol, asset_source, 
                                          datetime.combine(current_start_date, time.min), # time.min kullanÄ±ldÄ±
                                          datetime.combine(current_end_date, time.max)) # time.max kullanÄ±ldÄ±

    if not historical_data.empty:
        st.success(f"'{current_selected_asset}' iÃ§in {len(historical_data)} gÃ¼nlÃ¼k veri baÅŸarÄ±yla Ã§ekildi.")
        
        # GÃ¼ncel Fiyat DeÄŸiÅŸimini GÃ¶ster
        if len(historical_data) >= 2:
            latest_close = historical_data['Close'].iloc[-1]
            previous_close = historical_data['Close'].iloc[-2]
            price_change = latest_close - previous_close
            price_change_percent = (price_change / previous_close) * 100 if previous_close != 0 else 0

            delta_color = "inverse" if price_change < 0 else "normal"
            st.metric(
                label=f"Son KapanÄ±ÅŸ FiyatÄ± ({historical_data.index.max().strftime('%Y-%m-%d')})",
                value=f"{latest_close:.2f}",
                delta=f"{price_change:.2f} ({price_change_percent:.2f}%)",
                delta_color=delta_color
            )
        else:
            st.info("Fiyat deÄŸiÅŸimini gÃ¶stermek iÃ§in yeterli geÃ§miÅŸ veri yok (en az 2 gÃ¼n).")

        st.write("Ä°lk 5 veri satÄ±rÄ±:")
        st.dataframe(historical_data.head())
        
        processed_data = preprocess_data(historical_data, asset_symbol)

        if not processed_data.empty:
            st.success("Veriler baÅŸarÄ±yla iÅŸlendi ve Ã¶zellikler oluÅŸturuldu.")
            st.write("Ä°ÅŸlenmiÅŸ verinin son 5 satÄ±rÄ± (Ã¶zelliklerle birlikte):")
            st.dataframe(processed_data.tail())

            st.info(f"'{current_selected_asset}' iÃ§in model eÄŸitiliyor ve tahminler yapÄ±lÄ±yor...")
            
            model, scaler, features_list, future_predictions, rmse = model_training_and_prediction(processed_data, current_selected_asset, current_prediction_days)

            if model and future_predictions is not None:
                st.success("Model baÅŸarÄ±yla eÄŸitildi ve gelecek tahminler yapÄ±ldÄ±.")
                st.metric("Model RMSE (Ortalama Kare Hata):", f"{rmse:.4f}")

                # Tahmin tarihlerini oluÅŸtur
                prediction_dates = pd.date_range(start=historical_data.index.max() + timedelta(days=1), periods=current_prediction_days)
                
                # Bir sonraki gÃ¼nÃ¼n tahminini aÃ§Ä±kÃ§a gÃ¶ster
                if future_predictions:
                    next_day_date = prediction_dates[0]
                    next_day_prediction_value = future_predictions[0]
                    st.subheader(f"YarÄ±nki Tahmini KapanÄ±ÅŸ FiyatÄ± ({next_day_date.strftime('%Y-%m-%d')}) :orange[${next_day_prediction_value:,.2f}]") # Renklendirildi
                    
                    # YÃ¼zde deÄŸiÅŸimini hesapla ve gÃ¶ster
                    if not historical_data.empty and 'Close' in historical_data.columns and len(historical_data) > 0:
                        last_real_close = historical_data['Close'].iloc[-1]
                        if last_real_close != 0:
                            change_pct = ((next_day_prediction_value - last_real_close) / last_real_close) * 100
                            delta_color_pred = "inverse" if change_pct < 0 else "normal"
                            st.markdown(f"**DeÄŸiÅŸim:** :{'red' if change_pct < 0 else 'green'}["
                                        f"{change_pct:+.2f}% ({next_day_prediction_value - last_real_close:+.2f})] "
                                        f"{'â¬‡ï¸' if change_pct < 0 else 'â¬†ï¸'}")
                st.markdown("---")

                st.subheader(f"TÃ¼m {current_prediction_days} GÃ¼nlÃ¼k Gelecek Fiyat Tahminleri ({current_selected_asset})")
                predictions_df = pd.DataFrame({
                    "Tarih": prediction_dates,
                    "Tahmini KapanÄ±ÅŸ FiyatÄ±": future_predictions
                })
                predictions_df["Tahmini KapanÄ±ÅŸ FiyatÄ±"] = predictions_df["Tahmini KapanÄ±ÅŸ FiyatÄ±"].round(2)
                st.dataframe(predictions_df)

                # Tahminleri gÃ¶rselleÅŸtirme
                fig = go.Figure()

                # GeÃ§miÅŸ kapanÄ±ÅŸ fiyatlarÄ±
                fig.add_trace(go.Scatter(x=historical_data.index, y=historical_data['Close'], mode='lines', name='GeÃ§miÅŸ KapanÄ±ÅŸ FiyatÄ±', line=dict(color='blue')))

                # GerÃ§ek deÄŸerler (test setinden) - sadece gÃ¶rselleÅŸtirme iÃ§in, modelin kullandÄ±ÄŸÄ± gerÃ§ek test setidir.
                if len(processed_data) > FEATURE_LAG:
                    test_real_dates = processed_data.index[-FEATURE_LAG:]
                    test_real_values = processed_data['Close'].iloc[-FEATURE_LAG:]
                    fig.add_trace(go.Scatter(x=test_real_dates, y=test_real_values, mode='lines', name='GerÃ§ek DeÄŸerler (Test)', line=dict(color='green', dash='dot')))


                # Gelecek Tahminleri
                fig.add_trace(go.Scatter(x=prediction_dates, y=future_predictions, mode='lines+markers', name=f'Tahmini Fiyat ({current_prediction_days} GÃ¼n)', line=dict(color='red', dash='dash')))

                fig.update_layout(
                    title=f'{current_selected_asset} Fiyat Tahmini',
                    xaxis_title='Tarih',
                    yaxis_title='Fiyat',
                    hovermode='x unified',
                    legend_title="Veri Tipi",
                    height=600
                )
                st.plotly_chart(fig, use_container_width=True)

                st.subheader("Model ve Ã–lÃ§ekleyici Yolu")
                st.write(f"- Model yolu: `xgboost_model.joblib`")
                st.write(f"- Ã–lÃ§ekleyici yolu: `scaler.joblib`")
                st.write(f"- Ã–zellikler listesi yolu: `features.joblib`")
                st.warning("Not: Bu dosyalar uygulamanÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± dizinde oluÅŸturulur.")

            else:
                st.error("Model eÄŸitimi veya tahmini sÄ±rasÄ±nda bir sorun oluÅŸtu. LÃ¼tfen log dosyasÄ±na bakÄ±n.")
        else:
            st.error("Veri iÅŸleme sonrasÄ± boÅŸ kaldÄ±. LÃ¼tfen veri kaynaÄŸÄ±nÄ± ve tarih aralÄ±ÄŸÄ±nÄ± kontrol edin.")
    else:
        st.error(f"'{current_selected_asset}' iÃ§in geÃ§miÅŸ veri Ã§ekilemedi. LÃ¼tfen internet baÄŸlantÄ±nÄ±zÄ± veya seÃ§ilen varlÄ±ÄŸÄ±n sembolÃ¼nÃ¼/kaynaÄŸÄ±nÄ± kontrol edin. Log dosyasÄ±nda daha fazla detay bulabilirsiniz.")
