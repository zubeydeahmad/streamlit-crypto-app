# 03_news_sentiment_page.py
# (Haberler ve DuyarlÄ±lÄ±k Analizi)
# Bu dosya, haberleri web'den Ã§ekip duygu analizi yapan ayrÄ± bir Streamlit sayfasÄ± olarak tasarlanmÄ±ÅŸtÄ±r. DoÄŸrudan streamlit run 03_news_sentiment_page.py komutuyla Ã§alÄ±ÅŸtÄ±rÄ±labilir.
import streamlit as st
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import requests
from bs4 import BeautifulSoup
import logging

# Loglama yapÄ±landÄ±rmasÄ±
logging.basicConfig(filename='crypto_app.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

st.set_page_config(page_title="Haber ve DuyarlÄ±lÄ±k Analizi", layout="wide")

# NLTK'nÄ±n VADER sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ ve Punkt tokenizer'Ä± indirin (ilk Ã§alÄ±ÅŸtÄ±rmada bir kere yapÄ±lÄ±r)
# AyrÄ±ca, indirme iÅŸlemi sÄ±rasÄ±nda oluÅŸabilecek diÄŸer hatalarÄ± da yakalÄ±yoruz.
try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except LookupError:
    st.info("VADER lexicon bulunamadÄ±, indiriliyor...")
    try:
        nltk.download('vader_lexicon')
    except Exception as e:
        st.error(f"VADER lexicon indirilirken bir hata oluÅŸtu: {e}. LÃ¼tfen internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")
        logger.error(f"VADER lexicon indirme hatasÄ±: {e}")
except Exception as e:
    st.error(f"VADER lexicon kontrol edilirken beklenmeyen bir hata oluÅŸtu: {e}")
    logger.error(f"VADER lexicon kontrol hatasÄ±: {e}")

try:
    nltk.data.find('tokenizers/punkt.zip')
except LookupError:
    st.info("Punkt tokenizer bulunamadÄ±, indiriliyor...")
    try:
        nltk.download('punkt')
    except Exception as e:
        st.error(f"Punkt tokenizer indirilirken bir hata oluÅŸtu: {e}. LÃ¼tfen internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")
        logger.error(f"Punkt tokenizer indirme hatasÄ±: {e}")
except Exception as e:
    st.error(f"Punkt tokenizer kontrol edilirken beklenmeyen bir hata oluÅŸtu: {e}")
    logger.error(f"Punkt tokenizer kontrol hatasÄ±: {e}")


def get_news_headlines(url):
    """Belirli bir URL'den haber baÅŸlÄ±klarÄ±nÄ± Ã§ekmeye Ã§alÄ±ÅŸÄ±r."""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        headlines = []
        
        # Bu kÄ±sÄ±m her web sitesi iÃ§in Ã¶zelleÅŸtirilmelidir!
        # CoinDesk'in HTML yapÄ±sÄ± sÄ±kÃ§a deÄŸiÅŸebilir, bu seÃ§iciler gÃ¼ncel olmayabilir.
        # Genellikle baÅŸlÄ±klar h2, h3 etiketleri iÃ§inde veya belirli class'lara sahip div'ler iÃ§inde yer alÄ±r.
        
        # OlasÄ± CoinDesk baÅŸlÄ±k seÃ§icileri (gÃ¼ncel olanÄ± kontrol etmeniz gerekebilir):
        for h2_tag in soup.find_all('h2', class_='css-1a6v75g'):
            a_tag = h2_tag.find('a')
            if a_tag and a_tag.text:
                headlines.append(a_tag.text.strip())
        
        if not headlines:
            for div_tag in soup.find_all('div', class_='text-xl'):
                a_tag = div_tag.find('a')
                if a_tag and a_tag.text:
                    headlines.append(a_tag.text.strip())
        
        if not headlines:
            for title_tag in soup.find_all(['h1', 'h2', 'h3', 'h4']):
                if title_tag.find('a') and title_tag.find('a').text:
                    headlines.append(title_tag.find('a').text.strip())
                elif title_tag.text and len(title_tag.text.strip()) > 10:
                    headlines.append(title_tag.text.strip())

        logger.info(f"{len(headlines)} haber baÅŸlÄ±ÄŸÄ± Ã§ekildi.")
        return headlines
    except requests.exceptions.RequestException as e:
        st.error(f"Haber Ã§ekilirken aÄŸ hatasÄ± oluÅŸtu: {e}. LÃ¼tfen URL'yi ve internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")
        logger.error(f"Haber Ã§ekilirken aÄŸ hatasÄ±: {e}")
        return []
    except Exception as e:
        st.error(f"Haber Ã§ekilirken beklenmeyen bir hata oluÅŸtu: {e}")
        logger.error(f"Haber Ã§ekilirken beklenmeyen hata: {e}")
        return []

def analyze_sentiment(text_list):
    """Metin listesi iÃ§in duygu analizi yapar ve ortalama bileÅŸik skoru dÃ¶ndÃ¼rÃ¼r."""
    analyzer = SentimentIntensityAnalyzer()
    sentiments = []
    for text in text_list:
        vs = analyzer.polarity_scores(text)
        sentiments.append(vs['compound']) # BileÅŸik skor (-1.0 ile +1.0 arasÄ±)
    
    if sentiments:
        avg_sentiment = sum(sentiments) / len(sentiments)
        logger.info(f"Duygu analizi tamamlandÄ±. Ortalama skor: {avg_sentiment:.2f}")
        return avg_sentiment
    logger.info("Duygu analizi iÃ§in metin bulunamadÄ±.")
    return 0.0 # Haber yoksa nÃ¶tr


# --- Streamlit UygulamasÄ± ---
st.title("ğŸ“° Kripto Para Haberleri ve DuyarlÄ±lÄ±k Analizi")
st.markdown("Bu bÃ¶lÃ¼m, belirlediÄŸiniz bir kaynaktan (varsayÄ±lan: CoinDesk) haber baÅŸlÄ±klarÄ±nÄ± Ã§ekerek piyasa duyarlÄ±lÄ±ÄŸÄ±nÄ± analiz eder.")

coindesk_url = st.text_input("Haber KaynaÄŸÄ± URL'si (Ã¶rneÄŸin CoinDesk):", "https://www.coindesk.com/")

if st.button("Haberleri Ã‡ek ve Analiz Et"):
    with st.spinner("Haberler Ã§ekiliyor ve analiz ediliyor..."):
        news_headlines = get_news_headlines(coindesk_url)
        if news_headlines:
            st.subheader("Ã‡ekilen Haber BaÅŸlÄ±klarÄ±:")
            for i, headline in enumerate(news_headlines[:10]): # Ä°lk 10 baÅŸlÄ±ÄŸÄ± gÃ¶ster
                st.write(f"- {headline}")
            
            avg_sentiment = analyze_sentiment(news_headlines)
            
            st.subheader("Duygu Analizi Sonucu:")
            st.write(f"**Ortalama Duygu Skoru (VADER):** {avg_sentiment:.2f} (1.0 = Ã§ok pozitif, -1.0 = Ã§ok negatif)")

            if avg_sentiment > 0.1:
                st.success("Genel haber duyarlÄ±lÄ±ÄŸÄ± pozitif gÃ¶rÃ¼nÃ¼yor. Bu durum piyasa iÃ§in olumlu olabilir.")
            elif avg_sentiment < -0.1:
                st.error("Genel haber duyarlÄ±lÄ±ÄŸÄ± negatif gÃ¶rÃ¼nÃ¼yor. Bu durum piyasa iÃ§in olumsuz olabilir.")
            else:
                st.info("Genel haber duyarlÄ±lÄ±ÄŸÄ± nÃ¶tr gÃ¶rÃ¼nÃ¼yor.")
        else:
            st.warning("Haber baÅŸlÄ±klarÄ± Ã§ekilemedi veya site yapÄ±sÄ± deÄŸiÅŸmiÅŸ olabilir. LÃ¼tfen URL'yi ve sitenin HTML yapÄ±sÄ±nÄ± kontrol edin.")

st.markdown("---")
st.caption("Not: Web kazÄ±ma kodlarÄ±, hedef sitenin HTML yapÄ±sÄ± deÄŸiÅŸtiÄŸinde Ã§alÄ±ÅŸmayabilir. Profesyonel uygulamalar iÃ§in genellikle haber API'leri tercih edilir.")